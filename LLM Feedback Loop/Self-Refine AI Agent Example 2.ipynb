{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2b3506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !uv pip install langchain langgraph requests langchain-google-genai pygraphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ebdf37",
   "metadata": {},
   "source": [
    "### Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dcb664e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict, Optional\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Set your Google API key (replace with your actual key or load from .env)\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"\"\n",
    "\n",
    "# Initialize the Gemini model we'll use for all nodes\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92037bb3",
   "metadata": {},
   "source": [
    "### Define AI Agent's State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43b713b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict, total=False):\n",
    "    query: str\n",
    "    answer: Optional[str]\n",
    "    critique: Optional[str]\n",
    "    refined: Optional[str]\n",
    "    decision: Optional[str]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88023e74",
   "metadata": {},
   "source": [
    "### Define Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f17aeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_prompt = ChatPromptTemplate.from_template(\n",
    "    \"You are a helpful assistant. Answer the following query:\\n\\n{query}\"\n",
    ")\n",
    "\n",
    "reflect_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Here is the assistant's answer:\\n\\n{answer}\\n\\nPlease critique it and suggest improvements.\"\n",
    ")\n",
    "\n",
    "refine_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Original answer:\\n{answer}\\n\\nCritique:\\n{critique}\\n\\nPlease provide a refined, improved answer.\"\n",
    ")\n",
    "\n",
    "decision_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Here is the latest refined answer:\\n\\n{refined}\\n\\n\"\n",
    "    \"Question: Is this answer sufficient and high-quality? \"\n",
    "    \"Reply with only one word: 'yes' or 'no'.\"\n",
    ")\n",
    "\n",
    "# Chains together\n",
    "generate_chain = generate_prompt | llm\n",
    "reflect_chain = reflect_prompt | llm\n",
    "refine_chain = refine_prompt | llm\n",
    "decision_chain = decision_prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abb9cf8",
   "metadata": {},
   "source": [
    "### Define Node Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e66c0cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_node(state: AgentState):\n",
    "    result = generate_chain.invoke({\"query\": state[\"query\"]})\n",
    "    state[\"answer\"] = result.content\n",
    "    return state\n",
    "\n",
    "def reflect_node(state: AgentState):\n",
    "    result = reflect_chain.invoke({\"answer\": state[\"answer\"]})\n",
    "    state[\"critique\"] = result.content\n",
    "    return state\n",
    "\n",
    "def refine_node(state: AgentState):\n",
    "    result = refine_chain.invoke({\n",
    "        \"answer\": state[\"answer\"],\n",
    "        \"critique\": state[\"critique\"]\n",
    "    })\n",
    "    state[\"refined\"] = result.content\n",
    "    return state\n",
    "\n",
    "def decide_node(state: AgentState):\n",
    "    result = decision_chain.invoke({\"refined\": state[\"refined\"]})\n",
    "    state[\"decision\"] = result.content.strip().lower()\n",
    "    return state\n",
    "\n",
    "def decide_next(state: AgentState):\n",
    "    if state.get(\"decision\") == \"yes\":\n",
    "        return END\n",
    "    else:\n",
    "        return \"reflect\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d7082f",
   "metadata": {},
   "source": [
    "### Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea6ab960",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(AgentState)\n",
    "\n",
    "# Add Node\n",
    "graph.add_node(\"generate\", generate_node)\n",
    "graph.add_node(\"reflect\", reflect_node)\n",
    "graph.add_node(\"refine\", refine_node)\n",
    "graph.add_node(\"decide\", decide_node)\n",
    "\n",
    "# Set Entry Node\n",
    "graph.set_entry_point(\"generate\")\n",
    "\n",
    "# Connect Node (Add a Arrow to connect A Node and B Node)\n",
    "## \"Generate\" --> \"Reflect\"\n",
    "graph.add_edge(\"generate\", \"reflect\")\n",
    "## \"Reflect\" --> \"Refine\"\n",
    "graph.add_edge(\"reflect\", \"refine\")\n",
    "## \"Refine\" --> \"decide\"\n",
    "graph.add_edge(\"refine\", \"decide\")\n",
    "\n",
    "# Conditional edge from \"decide\"\n",
    "graph.add_conditional_edges(\"decide\", decide_next)\n",
    "\n",
    "# Compile\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94859c56",
   "metadata": {},
   "source": [
    "### Run Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7831c601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node 'generate':\n",
      "Why the image classifier have high accuracy but it fail to fulfill my expectation in classifying image. Please state in concise.\n",
      "High accuracy is typically on a specific test set. Your model likely suffers from **poor generalization** or a **mismatch between its training data and your real-world application's diverse or specific image conditions.**\n",
      "\n",
      "Output from node 'reflect':\n",
      "The assistant's answer correctly identifies the core issues: **poor generalization** and a **mismatch between training and real-world data**. These are indeed the most common reasons for a model performing well on a test set but failing in production.\n",
      "\n",
      "However, the answer is quite concise and could be significantly improved by:\n",
      "\n",
      "1.  **Elaborating on the concepts:** Briefly explaining *what* poor generalization and data mismatch mean.\n",
      "2.  **Providing actionable next steps/solutions:** The user is left with a diagnosis but no guidance on how to fix it.\n",
      "3.  **Offering to ask for more information:** To give more tailored advice.\n",
      "4.  **Improving the tone:** Making it slightly less blunt and more helpful.\n",
      "\n",
      "---\n",
      "\n",
      "### Critique:\n",
      "\n",
      "**Strengths:**\n",
      "\n",
      "*   **Correct Diagnosis:** Accurately pinpoints the fundamental problems (poor generalization, data mismatch).\n",
      "*   **Concise:** Gets straight to the point.\n",
      "*   **Highlights Key Terms:** Bolded terms are important concepts.\n",
      "\n",
      "**Weaknesses:**\n",
      "\n",
      "*   **Lack of Elaboration:** Doesn't explain *why* these issues occur or what they practically entail.\n",
      "*   **No Solutions/Next Steps:** This is the biggest gap. A user facing this problem needs guidance on how to proceed.\n",
      "*   **No Request for More Information:** Without knowing the specific application, image types, or model, the advice can only be generic. Asking for more details would allow for more targeted suggestions.\n",
      "*   **Slightly Blunt Tone:** While directness can be good, it could be softened with a more empathetic and guiding approach.\n",
      "\n",
      "---\n",
      "\n",
      "### Suggested Improvements:\n",
      "\n",
      "Here's an improved version that addresses the weaknesses:\n",
      "\n",
      "---\n",
      "\n",
      "**Improved Assistant's Answer:**\n",
      "\n",
      "\"You've hit on a very common and frustrating problem in machine learning! Your observation that the model has high accuracy on a test set but performs poorly in the real world strongly indicates two related issues:\n",
      "\n",
      "1.  **Poor Generalization (often due to Overfitting):** Your model has likely learned to perform exceptionally well on the specific patterns and noise present in your training and test data, but it hasn't learned the underlying, broader concepts that allow it to perform well on *unseen, real-world* variations. It's memorized the answers rather than understanding the subject.\n",
      "2.  **Mismatch Between Training Data and Real-World Conditions (Domain Shift):** The images your model encounters in the real world are likely significantly different from those it was trained on. This could be due to:\n",
      "    *   **Different Lighting:** Varying brightness, shadows, glare.\n",
      "    *   **Different Angles/Perspectives:** Objects appearing from new viewpoints.\n",
      "    *   **Background Clutter/Occlusions:** More distractions or partial blockages.\n",
      "    *   **Image Quality:** Different resolutions, compression artifacts, noise levels.\n",
      "    *   **New Object Variations:** Subtle differences in the objects themselves that weren't in the training set.\n",
      "    *   **Environmental Factors:** Weather, time of day, different camera sensors.\n",
      "\n",
      "**To address this, here are several strategies you can explore:**\n",
      "\n",
      "**1. Data-Centric Solutions (Most Impactful):**\n",
      "\n",
      "*   **Expand and Diversify Your Training Data:** This is often the most effective solution. Collect more real-world images that truly represent the diverse conditions your model will encounter in production. Focus on edge cases where your model currently fails.\n",
      "*   **Robust Data Augmentation:** Apply a wider range of transformations to your existing training data (e.g., random rotations, shifts, zooms, brightness changes, contrast adjustments, adding noise, blurring, color jitter, cutmix/mixup). This helps the model see more variations without needing to collect entirely new images.\n",
      "*   **Domain Adaptation / Transfer Learning:** If you have a small amount of real-world data, fine-tune your pre-trained model on this specific real-world dataset. This helps the model adapt to the new domain.\n",
      "*   **Synthetic Data Generation:** If real data collection is hard, explore generating synthetic data that mimics real-world conditions, though this can be complex to do effectively.\n",
      "\n",
      "**2. Model-Centric Solutions:**\n",
      "\n",
      "*   **Regularization Techniques:** Implement or increase regularization (e.g., Dropout, L1/L2 regularization) during training. This discourages the model from becoming too complex and memorizing the training data.\n",
      "*   **Simpler Model Architecture:** Sometimes, a simpler model with fewer parameters generalizes better than an overly complex one, especially with limited data.\n",
      "*   **Feature Engineering (if applicable):** If you're not using end-to-end deep learning, carefully engineered features that are robust to real-world variations can help.\n",
      "\n",
      "**3. Evaluation-Centric Solutions:**\n",
      "\n",
      "*   **Create a Representative Test Set:** Ensure your test set accurately reflects the diversity and challenges of your real-world application. It should include images from the \"problematic\" conditions.\n",
      "*   **Perform Error Analysis:** Don't just look at overall accuracy. Analyze the specific types of images and conditions where your model fails in the real world. This will guide your data collection and augmentation efforts.\n",
      "*   **Cross-Validation:** Use k-fold cross-validation during development to get a more robust estimate of your model's performance and generalization ability.\n",
      "\n",
      "**To give you more specific advice, could you tell me a bit more about:**\n",
      "\n",
      "*   **What kind of images are you working with?** (e.g., medical, industrial, natural scenes, faces)\n",
      "*   **What is the specific task?** (e.g., classification, object detection, segmentation)\n",
      "*   **What are the typical differences between your training data and the real-world images?**\n",
      "*   **What model architecture are you using?**\"\n",
      "\n",
      "---\n",
      "\n",
      "**Why this is better:**\n",
      "\n",
      "*   **Explains the \"Why\":** Users understand *what* poor generalization and domain shift mean in practical terms.\n",
      "*   **Provides Actionable Steps:** Offers concrete, categorized solutions that the user can immediately start investigating.\n",
      "*   **Prioritizes Solutions:** Starts with data-centric solutions, which are often the most impactful for this problem.\n",
      "*   **Asks for More Information:** Shows a willingness to provide tailored advice and guides the user on what details would be helpful.\n",
      "*   **Improved Tone:** More helpful, diagnostic, and guiding.\n",
      "*   **Structured for Readability:** Uses bullet points and bolding to make the information easy to digest.\n",
      "\n",
      "Output from node 'refine':\n",
      "You've hit on a very common and often frustrating problem in machine learning! Your observation that the model has high accuracy on a specific test set but performs poorly in the real world strongly indicates two related core issues:\n",
      "\n",
      "1.  **Poor Generalization (often due to Overfitting):** Your model has likely learned to perform exceptionally well on the specific patterns, features, and even noise present in your training and test data. However, it hasn't learned the underlying, broader concepts that allow it to perform robustly on *unseen, real-world* variations. Think of it as memorizing answers rather than truly understanding the subject.\n",
      "\n",
      "2.  **Mismatch Between Training Data and Real-World Conditions (Domain Shift):** The images your model encounters in the real world are likely significantly different from those it was trained on. This \"shift\" in data distribution can be caused by various factors:\n",
      "    *   **Environmental Differences:** Varying lighting (brightness, shadows, glare), weather conditions, time of day.\n",
      "    *   **Perspective & Pose:** Objects appearing from different angles, distances, or orientations.\n",
      "    *   **Background Clutter/Occlusions:** More distractions, partial blockages, or complex backgrounds in real-world scenes.\n",
      "    *   **Image Quality:** Different resolutions, compression artifacts, sensor noise, blur, or focus issues.\n",
      "    *   **Object Variations:** Subtle differences in the objects themselves (e.g., different brands, wear and tear) that weren't represented in the training set.\n",
      "    *   **Camera/Sensor Differences:** Images captured by different types of cameras or sensors can have distinct characteristics.\n",
      "\n",
      "**To address this, here are several strategies you can explore, starting with the most impactful:**\n",
      "\n",
      "### 1. Data-Centric Solutions (Often the Most Effective)\n",
      "\n",
      "*   **Expand and Diversify Your Training Data:** This is frequently the most powerful solution. Collect more real-world images that truly represent the diverse conditions your model will encounter in production. Focus specifically on \"edge cases\" or scenarios where your model currently fails.\n",
      "*   **Robust Data Augmentation:** Apply a wider and more realistic range of transformations to your existing training data (e.g., random rotations, shifts, zooms, brightness changes, contrast adjustments, adding noise, blurring, color jitter, cutmix/mixup). This helps the model see more variations without needing to collect entirely new images.\n",
      "*   **Domain Adaptation / Transfer Learning:** If you have a small amount of real-world data, fine-tune your pre-trained model on this specific real-world dataset. This helps the model adapt to the new domain's characteristics.\n",
      "*   **Synthetic Data Generation:** If real data collection is difficult or expensive, explore generating synthetic data that closely mimics real-world conditions, though this can be complex to do effectively.\n",
      "\n",
      "### 2. Model-Centric Solutions\n",
      "\n",
      "*   **Regularization Techniques:** Implement or increase regularization (e.g., Dropout, L1/L2 regularization) during training. This discourages the model from becoming too complex and memorizing the training data, promoting better generalization.\n",
      "*   **Simpler Model Architecture:** Sometimes, a simpler model with fewer parameters generalizes better than an overly complex one, especially with limited or noisy data.\n",
      "*   **Feature Engineering (if applicable):** If you're not using end-to-end deep learning, carefully engineered features that are robust to real-world variations can significantly help.\n",
      "\n",
      "### 3. Evaluation-Centric Solutions\n",
      "\n",
      "*   **Create a Representative Test Set:** Ensure your test set accurately reflects the diversity and challenges of your real-world application. It should include images from the \"problematic\" conditions where your model currently fails. This is crucial for reliable evaluation.\n",
      "*   **Perform Error Analysis:** Don't just look at overall accuracy. Systematically analyze the specific types of images and conditions where your model fails in the real world. This will provide invaluable insights to guide your data collection, augmentation, and model improvement efforts.\n",
      "*   **Cross-Validation:** Use k-fold cross-validation during development to get a more robust estimate of your model's performance and generalization ability across different data splits.\n",
      "\n",
      "---\n",
      "\n",
      "**To give you more specific and tailored advice, could you tell me a bit more about:**\n",
      "\n",
      "*   **What kind of images are you working with?** (e.g., medical scans, industrial parts, natural scenes, faces, satellite imagery)\n",
      "*   **What is the specific task?** (e.g., image classification, object detection, semantic segmentation, anomaly detection)\n",
      "*   **What are the typical differences you've observed between your training data and the real-world images?** (e.g., \"real-world images are much darker,\" \"objects are often partially obscured,\" \"different camera angles\")\n",
      "*   **What model architecture are you currently using?**\n",
      "\n",
      "Output from node 'decide':\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'decide'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m node \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecide\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdecide\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m()\n",
      "\u001b[1;31mKeyError\u001b[0m: 'decide'"
     ]
    }
   ],
   "source": [
    "inputs = {\"query\": \"Why the image classifier have high accuracy but it fail to fulfill my expectation in classifying image. Please state in concise.\"}\n",
    "\n",
    "for output in app.stream(inputs):\n",
    "    for node, state in output.items():\n",
    "        print(f\"Output from node '{node}':\")\n",
    "\n",
    "        if node == \"generate\":\n",
    "            print(state[\"query\"])\n",
    "            print(state[\"answer\"])\n",
    "            print()\n",
    "        elif node == \"reflect\":\n",
    "            print(state[\"critique\"])\n",
    "            print()\n",
    "        elif node == \"refine\":\n",
    "            print(state[\"refined\"])\n",
    "            print()\n",
    "        elif node == \"decide\":\n",
    "            print(state[\"decision\"])\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc08285f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(app.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea58915f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
